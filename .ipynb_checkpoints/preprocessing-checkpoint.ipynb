{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77de93e4",
   "metadata": {
    "id": "77de93e4"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "EnG-1KsiOp7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnG-1KsiOp7d",
    "outputId": "af8f0bc4-cd64-4281-c5f3-6fafeff99ca9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NgNYHv8MPOgK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgNYHv8MPOgK",
    "outputId": "6b96833a-eb46-4440-97d6-63a3bd611db2"
   },
   "outputs": [],
   "source": [
    "# %cd drive/MyDrive/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08931560",
   "metadata": {
    "id": "08931560"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train/SemEval2018-T3-train-taskA.txt\", sep='\\t', lineterminator='\\n', encoding='utf-8')\n",
    "df_test = pd.read_csv(\"goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt\", sep='\\t', lineterminator='\\n', encoding='utf-8')\n",
    "df_replace = pd.read_csv(\"test_TaskA/SemEval2018-T3_input_test_taskA.txt\", sep='\\t', lineterminator='\\n', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90da0270",
   "metadata": {
    "id": "90da0270",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Temp\\ipykernel_16780\\943452490.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_test, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_test['Tweet text'] = df_test['Tweet text'].apply(emoji.demojize)\n",
    "\n",
    "df = df.append(df_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a3b9ce",
   "metadata": {
    "id": "b2a3b9ce"
   },
   "outputs": [],
   "source": [
    "def word_counter(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if not x.startswith((\"@\", \"#\"))]\n",
    "    return len(newlist)\n",
    "\n",
    "def tag_counter(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if x.startswith(\"@\")]\n",
    "    return len(newlist)\n",
    "\n",
    "def hashtag_counter(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if x.startswith(\"#\")]\n",
    "    return len(newlist)\n",
    "\n",
    "def has_emoji(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if x != \":\" and x.startswith(\":\") and x.endswith(\":\")]\n",
    "    return len(newlist)\n",
    "\n",
    "def clean_text(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if not x.startswith((\":\", \"@\", \"#\"))]\n",
    "    return ' '.join(newlist)\n",
    "\n",
    "### dodani featuresi ###\n",
    "def link_counter(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if x.startswith(('http:', 'https:'))]\n",
    "    return len(newlist)\n",
    "\n",
    "def smiley_counter(s):\n",
    "    splitted = s.split()\n",
    "    newlist = [x for x in splitted if not re.match(r'([\\:\\;\\=][\\(\\)PD]+)+', x)]\n",
    "    return len(newlist)\n",
    "\n",
    "def exclamation_mark_counter(s):\n",
    "    return s.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf2d164",
   "metadata": {
    "id": "aaf2d164"
   },
   "outputs": [],
   "source": [
    "df['length'] = df['Tweet text'].apply(len)\n",
    "df['word_count'] = df['Tweet text'].apply(word_counter)\n",
    "df['tag_count'] = df['Tweet text'].apply(tag_counter)\n",
    "df['hashtag_count'] = df['Tweet text'].apply(hashtag_counter)\n",
    "df['link_count'] = df['Tweet text'].apply(link_counter)\n",
    "df['smiley_count'] = df['Tweet text'].apply(smiley_counter)\n",
    "df['exclamation_mark_count'] = df['Tweet text'].apply(exclamation_mark_counter)\n",
    "df['has_emoji'] = df['Tweet text'].apply(has_emoji)\n",
    "df['clean_text'] = df['Tweet text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f375058",
   "metadata": {
    "id": "9f375058"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a32175c",
   "metadata": {
    "id": "9a32175c"
   },
   "outputs": [],
   "source": [
    "# ###lista svih listi tokena\n",
    "\n",
    "# all_tokens_list = []\n",
    "# for index, row in df.iterrows():\n",
    "#     token_list = []\n",
    "#     doc = nlp(row['clean_text'])\n",
    "#     for token in doc:\n",
    "#         token_list.append(token)\n",
    "#     all_tokens_list.append(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7739051",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81215b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You're never too old for Footie Pajamas. http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nothing makes me happier then getting on the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4:30 an opening my first beer now gonna be a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Adam_Klug do you think you would support a gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@samcguigan544 You are not allowed to open tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oh, thank GOD - our entire office email system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>But instead, I'm scrolling through Facebook, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@TargetZonePT :pouting_face: no he bloody isn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cold or warmth both suffuse one's cheeks with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Just great when you're mobile bill arrives by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Tweet text\n",
       "0   Sweet United Nations video. Just in time for C...\n",
       "1   @mrdahl87 We are rumored to have talked to Erv...\n",
       "2   Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3                 3 episodes left I'm dying over here\n",
       "4   I can't breathe! was chosen as the most notabl...\n",
       "5   You're never too old for Footie Pajamas. http:...\n",
       "6   Nothing makes me happier then getting on the h...\n",
       "7   4:30 an opening my first beer now gonna be a l...\n",
       "8   @Adam_Klug do you think you would support a gu...\n",
       "9   @samcguigan544 You are not allowed to open tha...\n",
       "10  Oh, thank GOD - our entire office email system...\n",
       "11  But instead, I'm scrolling through Facebook, I...\n",
       "12  @TargetZonePT :pouting_face: no he bloody isn'...\n",
       "13  Cold or warmth both suffuse one's cheeks with ...\n",
       "14  Just great when you're mobile bill arrives by ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = df[['Tweet text']]\n",
    "tweet_text.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "969535cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_words(s):\n",
    "    '''Removes tags, emojis, links, smiley faces, hashtag signs, stopwords and changes the case to lower.'''\n",
    "    ret_list = []\n",
    "\n",
    "    is_tag = lambda w: w.startswith('@')\n",
    "    is_emoji = lambda w: w != \":\" and w.startswith(\":\") and w.endswith(\":\")\n",
    "    is_link = lambda w: w.startswith(\"http:\") or w.startswith(\"https:\")\n",
    "    is_hashtag = lambda w: w.startswith(\"#\")\n",
    "    is_smiley = lambda w: re.match(r'([\\:\\;\\=][\\(\\)PD]+)+', w)\n",
    "    is_not_stopword = lambda w: w not in nlp.Defaults.stop_words\n",
    "    \n",
    "    for i, s_i in enumerate(s):\n",
    "        w_arr = s_i.split()\n",
    "        w2 = []\n",
    "        for w in w_arr:\n",
    "            if is_tag(w) or is_emoji(w) or is_link(w):\n",
    "                pass\n",
    "            \n",
    "            elif is_hashtag(w):\n",
    "                w_tmp = w.replace('#', '')\n",
    "                if w_tmp != '':\n",
    "                    w2.append(w_tmp.lower())\n",
    "            \n",
    "            elif is_smiley(w):\n",
    "                w_tmp = re.sub(r'([\\:\\;\\=][\\(\\)PD]+)+', '', w)\n",
    "                if w_tmp != '':\n",
    "                    w2.append(w_tmp.lower())\n",
    "            \n",
    "#             else:\n",
    "#                 w2.append(w.lower())\n",
    "            \n",
    "            elif is_not_stopword(w):\n",
    "                w2.append(w.lower())\n",
    "            \n",
    "        ret_list.append(' '.join(w2))\n",
    "    return ret_list\n",
    "\n",
    "tweet_text = tweet_text.apply(preprocess_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec955f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(s):\n",
    "    '''Lemmatizes the words in the sentences'''\n",
    "    return [[w.lemma_ for w in nlp(s_i)] for s_i in s]\n",
    "\n",
    "def join_docs(s):\n",
    "    '''Joins the strings inside the inner list of a nested list'''\n",
    "    return [' '.join([w for w in s_i]) for s_i in s]\n",
    "\n",
    "tweet_text = tweet_text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25bdf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'winner', 'go', 'stock', '!', 'they', 'bribe', 'I', '.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['what', 'b.e.a.utiful', 'day', 'scotland', '!', '!', 'rain', 'gale', 'lol']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['you', 'be', '\"', 'people', 'who', 'antagonize', 'I', '\"', 'list', '.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_text_punc = [[w for w in s_i] for s_i in tweet_text['Tweet text']]\n",
    "\n",
    "display(tweet_text_punc[1401])\n",
    "display(tweet_text_punc[1416])\n",
    "display(tweet_text_punc[1428])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d560761",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = join_docs(tweet_text['Tweet text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937f96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_preprocess(s):\n",
    "    '''Uses gensims preprocess function to prepare the data for topic modeling'''\n",
    "    return [simple_preprocess(s_i, deacc=True) for s_i in s]\n",
    "\n",
    "tweet_text = gensim_preprocess(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c764599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'winner', 'go', 'stock', 'they', 'bribe']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['what', 'utiful', 'day', 'scotland', 'rain', 'gale', 'lol']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['you', 'be', 'people', 'who', 'antagonize', 'list']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tweet_text[1401])\n",
    "display(tweet_text[1416])\n",
    "display(tweet_text[1428])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5733cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = corpora.Dictionary(tweet_text)\n",
    "d.filter_extremes(no_below=35, no_above=0.5)\n",
    "\n",
    "doc_term_matrix = [d.doc2bow(w) for w in tweet_text]\n",
    "doc_term_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07e333c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27bad45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:18<00:00,  1.40s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#         coh = CoherenceModel(model=lda, texts=tweet_text, dictionary=d)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#         coherence_values[i] = coh.get_coherence()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models\u001b[38;5;66;03m#, coherence, coherence_values\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m models, coherence, coherence_values \u001b[38;5;241m=\u001b[39m calculate_coherence_values(doc_term_matrix, d, tweet_text)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "def calculate_coherence_values(doc_term_matrix, d, tweet_text):\n",
    "    models, coherence = [], []\n",
    "    coherence_values = {}\n",
    "    \n",
    "    for i in tqdm(range(2, 40, 3)):\n",
    "        lda = gensim.models.LdaMulticore(doc_term_matrix, num_topics=i, id2word=d, passes=1, workers=12)\n",
    "        models.append(lda)\n",
    "\n",
    "        coh = CoherenceModel(model=lda, texts=tweet_text, dictionary=d)\n",
    "        coherence_values[i] = coh.get_coherence()\n",
    "    \n",
    "    return models, coherence, coherence_values\n",
    "\n",
    "models, coherence, coherence_values = calculate_coherence_values(doc_term_matrix, d, tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(coherence_values.keys()), list(coherence_values.values()), '-o')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.title('Coherence score compared to number of topics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2076f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.230*\"be\" + 0.067*\"that\" + 0.057*\"you\" + 0.039*\"people\" + 0.036*\"my\" + 0.034*\"we\" + 0.030*\"what\" + 0.029*\"they\" + 0.025*\"one\" + 0.024*\"watch\"'),\n",
       " (1,\n",
       "  '0.248*\"not\" + 0.112*\"do\" + 0.054*\"can\" + 0.038*\"time\" + 0.037*\"like\" + 0.032*\"sarcasm\" + 0.030*\"love\" + 0.028*\"will\" + 0.025*\"sleep\" + 0.025*\"wait\"'),\n",
       " (2,\n",
       "  '0.078*\"the\" + 0.059*\"get\" + 0.055*\"good\" + 0.047*\"irony\" + 0.046*\"want\" + 0.042*\"to\" + 0.034*\"this\" + 0.030*\"and\" + 0.029*\"right\" + 0.029*\"think\"'),\n",
       " (3,\n",
       "  '0.121*\"be\" + 0.113*\"it\" + 0.087*\"day\" + 0.033*\"way\" + 0.032*\"ve\" + 0.028*\"thing\" + 0.024*\"no\" + 0.023*\"find\" + 0.023*\"life\" + 0.023*\"new\"'),\n",
       " (4,\n",
       "  '0.084*\"love\" + 0.055*\"go\" + 0.042*\"thank\" + 0.037*\"year\" + 0.037*\"oh\" + 0.036*\"so\" + 0.035*\"well\" + 0.032*\"today\" + 0.030*\"come\" + 0.030*\"make\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = gensim.models.LdaMulticore(doc_term_matrix, num_topics=5, id2word=d, passes=20, workers=12)\n",
    "\n",
    "k = 5 # mjesto gdje je prvi lakat\n",
    "best = lda # models[k]\n",
    "best.print_topics()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
