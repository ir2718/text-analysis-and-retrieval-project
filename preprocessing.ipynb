{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "77de93e4",
      "metadata": {
        "id": "77de93e4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnG-1KsiOp7d",
        "outputId": "af8f0bc4-cd64-4281-c5f3-6fafeff99ca9"
      },
      "id": "EnG-1KsiOp7d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgNYHv8MPOgK",
        "outputId": "6b96833a-eb46-4440-97d6-63a3bd611db2"
      },
      "id": "NgNYHv8MPOgK",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "08931560",
      "metadata": {
        "id": "08931560"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train/SemEval2018-T3-train-taskA.txt\", sep='\\t', lineterminator='\\n')\n",
        "df_test = pd.read_csv(\"goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt\", sep='\\t', lineterminator='\\n')\n",
        "df_replace = pd.read_csv(\"test_TaskA/SemEval2018-T3_input_test_taskA.txt\", sep='\\t', lineterminator='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "90da0270",
      "metadata": {
        "id": "90da0270"
      },
      "outputs": [],
      "source": [
        "df_test['Tweet text'] = df_test['Tweet text'].apply(emoji.demojize)\n",
        "\n",
        "df = df.append(df_test, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b2a3b9ce",
      "metadata": {
        "id": "b2a3b9ce"
      },
      "outputs": [],
      "source": [
        "def word_counter(s):\n",
        "    splitted = s.split()\n",
        "    newlist = [x for x in splitted if not x.startswith((\"@\", \"#\"))]\n",
        "    return len(newlist)\n",
        "\n",
        "def tag_counter(s):\n",
        "    splitted = s.split()\n",
        "    newlist = [x for x in splitted if x.startswith(\"@\")]\n",
        "    return len(newlist)\n",
        "\n",
        "def hashtag_counter(s):\n",
        "    splitted = s.split()\n",
        "    newlist = [x for x in splitted if x.startswith(\"#\")]\n",
        "    return len(newlist)\n",
        "\n",
        "def has_emoji(s):\n",
        "    splitted = s.split()\n",
        "    newlist = [x for x in splitted if x != \":\" and x.startswith(\":\") and x.endswith(\":\")]\n",
        "    return len(newlist)\n",
        "\n",
        "def clean_text(s):\n",
        "    splitted = s.split()\n",
        "    newlist = [x for x in splitted if not x.startswith((\":\", \"@\", \"#\"))]\n",
        "    return ' '.join(newlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aaf2d164",
      "metadata": {
        "id": "aaf2d164"
      },
      "outputs": [],
      "source": [
        "df['length'] = df['Tweet text'].apply(len)\n",
        "df['word_count'] = df['Tweet text'].apply(word_counter)\n",
        "df['tag_count'] = df['Tweet text'].apply(tag_counter)\n",
        "df['hashtag_count'] = df['Tweet text'].apply(hashtag_counter)\n",
        "df['has_emoji'] = df['Tweet text'].apply(has_emoji)\n",
        "df['clean_text'] = df['Tweet text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f375058",
      "metadata": {
        "id": "9f375058"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9a32175c",
      "metadata": {
        "id": "9a32175c"
      },
      "outputs": [],
      "source": [
        "###lista svih listi tokena\n",
        "\n",
        "all_tokens_list = []\n",
        "for index, row in df.iterrows():\n",
        "    token_list = []\n",
        "    doc = nlp(row['clean_text'])\n",
        "    for token in doc:\n",
        "        token_list.append(token)\n",
        "    all_tokens_list.append(token_list)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}